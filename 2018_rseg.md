# EPAM Systems

## Period

Nov, 2018 - Jul, 2020

## Job Position

Software Engineer

## Project Roles

Developer

## Customer

RSEG Group

## Company URL

<https://www.rseg.com/>

## Description

- **RSEG-008**: Implementation of scrapers and parsers for a data pipeline

## Participation

I started working on the application from the very early stage of creating of POC. Then, I continued improving functionality and reliability by implementation of new features, code refactoring and test covering. As the result we developed production ready robust ETL solution that handle hundreds of websites to gather hundreds of gigabytes of up-to-date structured data.

I participated in all parts of the application's development, including:

- Website scrapers, based on HTTP-requests and controlling of a web-browser
- File parsers that read, clean and transform data in various formats (CSV, PARQUET, AVRO, etc.)
- Development of interaction with a DB and a cloud file strorage
- Creating unit/functional tests
- Containerization by Docker, Docker-compose
- Creating of JSON configs with instructions for scraping/parsing of data sources

## Team

- Dev team: 5 members
- QA team: 3 members

## Database

Microsoft SQL Server, JSON

## Tools

Jira, GitHub, Azure, Pycharm, Docker

## Technologies

- **Programing**: Python
- **Retrieving content from websites**: Selenium, Requests
- **HTML parsing**: XPATH quering by Lxml/Selenium, Beautiful Soup
- **Data parsing**: Pandas (CSV, AVRO, etc.), Objectpath (JSON), Tabula (PDF), xlrd/xlwt (XLS)
- **Database interaction**: SQLAlchemy, Alembic, TinyDB
- **Storing configuration/instructions for scrapers and parsers**: JSON, YAML
- **Testing**: Unittest, Flake8
- **Containerization**: Docker, Docker-compose
- **Cloud (Azure)**:
  - *Execution*: Container Registry/Instances, Logic Apps
  - *File storage*: Blob Storage
  - *Data storage*: Data Lake Storage
  - *Metadata Storage*: SQL Database
